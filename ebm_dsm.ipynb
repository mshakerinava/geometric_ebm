{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiJVbWMG2l76"
   },
   "source": [
    "## GPU Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "td8TWH2HKqZT",
    "outputId": "65c8c194-f57e-4fc0-c2e0-830e454b1d83"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import imageio\n",
    "import colorsys\n",
    "import multiprocessing as mp\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from tqdm import tqdm\n",
    "import geoopt\n",
    "\n",
    "from data import sample_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 256\n",
    "        self.epochs = 10\n",
    "        self.lr = 3e-3\n",
    "        # self.save = True\n",
    "        # self.save_path = './noise_pred_gen.pt'\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.dataset = 'checkerboard' # mnist, 2spirals, checkerboard, rings, 8gaussians\n",
    "        self.manifold = 'sphere' # sphere, none (euclidean)\n",
    "        self.size = int(1e6) # dataset size\n",
    "        self.min_noise = 0.01 # TODO: score can be very large! How do we solve this?\n",
    "        self.max_noise = 0.1\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_kwargs = dict(shuffle=True, batch_size=args.batch_size, num_workers=4, drop_last=True)\n",
    "\n",
    "if args.dataset == 'mnist':\n",
    "    mnist_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "    mnist_train = MNIST(root='./data', train=True, download=True, transform=mnist_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(mnist_train, **data_loader_kwargs)\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(sample_2d(args.dataset, 100000), **data_loader_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere = geoopt.Sphere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_on_sphere(x, r=6):\n",
    "    z = torch.sqrt(r ** 2 - x[:, 0] ** 2 - x[:, 1] ** 2)\n",
    "    return torch.stack((x[:, 0], x[:, 1], z), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Gaussian noise to a batch of data points\n",
    "def add_noise(x, noise_strengths, manifold):\n",
    "    # if noise_strengths is not a tensor, make it a tensor\n",
    "    if not isinstance(noise_strengths, torch.Tensor):\n",
    "        noise_strengths = torch.tensor(noise_strengths, device=x.device)\n",
    "    assert x.shape[0:1] == noise_strengths.shape\n",
    "    B = x.shape[0]\n",
    "    dim = np.mul(x.shape[1:])\n",
    "    orig_shape = x.shape\n",
    "    x = x.view(B, -1)\n",
    "    noise_strengths = noise_strengths.view(B, 1)\n",
    "    noise = torch.randn_like(x) * noise_strengths\n",
    "\n",
    "    if manifold == 'sphere':\n",
    "        noise[:, -1] = 0\n",
    "        z1 = torch.zeros(dim, device=x.device)\n",
    "        z1[-1] = 1\n",
    "        noise = sphere.transp(z1, x, noise)\n",
    "        noisy_x = sphere.expmap(x, noise)\n",
    "    else:\n",
    "        noisy_x = x + noise\n",
    "\n",
    "    return noisy_x.view(orig_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # get one batch from train_loader\n",
    "# # for batch_idx, (data, target) in enumerate(train_loader):\n",
    "# #     break\n",
    "\n",
    "# # data = data[:10]\n",
    "# x = sample_2d(args.dataset, 1000)\n",
    "\n",
    "# # # plot images side-by-side in matplotlib\n",
    "# # def plot_images(images):\n",
    "# #     assert len(images.shape) == 4\n",
    "# #     fig, axes = plt.subplots(1, len(images), figsize=(10, 10))\n",
    "# #     for i, img in enumerate(images):\n",
    "# #         if images.shape[1] == 1:\n",
    "# #             img = img.squeeze(0)\n",
    "# #             axes[i].imshow(img, cmap='gray')\n",
    "# #         else:\n",
    "# #             axes[i].imshow(img)\n",
    "# #         axes[i].axis('off')\n",
    "# #     plt.show()\n",
    "\n",
    "# # plot_images(data.numpy())\n",
    "# # print(data.max())\n",
    "\n",
    "# # noise_strengths = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# # noisy_images = add_noise(data, noise_strengths)\n",
    "\n",
    "# noisy_x_min = add_noise(x, np.ones(x.shape[0]) * args.min_noise)\n",
    "# noisy_x_med = add_noise(x, np.ones(x.shape[0]) * (args.min_noise + args.max_noise) / 2)\n",
    "# noisy_x_max = add_noise(x, np.ones(x.shape[0]) * args.max_noise)\n",
    "\n",
    "# # 4 by 1 scatter plots\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# axes[0].scatter(x[:, 0], x[:, 1], s=1)\n",
    "# axes[0].scatter(noisy_x_min[:, 0], noisy_x_min[:, 1], s=1)\n",
    "# axes[0].set_title('noise = {}'.format(args.min_noise))\n",
    "\n",
    "# axes[1].scatter(x[:, 0], x[:, 1], s=1)\n",
    "# axes[1].scatter(noisy_x_med[:, 0], noisy_x_med[:, 1], s=1)\n",
    "# axes[1].set_title('noise = {}'.format((args.min_noise + args.max_noise) / 2))\n",
    "\n",
    "# axes[2].scatter(x[:, 0], x[:, 1], s=1)\n",
    "# axes[2].scatter(noisy_x_max[:, 0], noisy_x_max[:, 1], s=1)\n",
    "# axes[2].set_title('noise = {}'.format(args.max_noise))\n",
    "\n",
    "# # for i in range(10):\n",
    "# #     print('noise estimate: %.6f | true noise: %.6f' % (torch.sqrt(torch.mean((data[i] - noisy_images[i]) ** 2)).item(), noise_strengths[i]))\n",
    "\n",
    "# # plot_images(noisy_images.numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample_2d(args.dataset, 1000)\n",
    "x_ = project_on_sphere(x, r=5)\n",
    "noisy_x = add_noise(x_, torch.ones(x.shape[0], device=args.device) * args.min_noise)\n",
    "\n",
    "# 3d plot of x_\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(x_[:, 0], x_[:, 1], x_[:, 2], s=1)\n",
    "ax.scatter(noisy_x[:, 0], noisy_x[:, 1], noisy_x[:, 2], s=1)\n",
    "\n",
    "ax.set_xlim(-1.1, 1.1)\n",
    "ax.set_ylim(-1.1, 1.1)\n",
    "ax.set_zlim(-1.1, 1.1)\n",
    "\n",
    "# plot a transparent sphere of radius 1\n",
    "u, v = np.mgrid[0:2*np.pi:20j, 0:np.pi:10j]\n",
    "x = np.cos(u)*np.sin(v)\n",
    "y = np.sin(u)*np.sin(v)\n",
    "z = np.cos(v)\n",
    "ax.plot_wireframe(x, y, z, color=\"r\", alpha=0.1)\n",
    "\n",
    "# look at plot from 45 degree angle\n",
    "ax.view_init(60, 60)\n",
    "\n",
    "# savefig\n",
    "plt.savefig('sphere.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    ''' Wraps around a neural network and adds methods such as `save`, `load`, and `run`. '''\n",
    "    def __init__(self, net_body):\n",
    "        super(Network, self).__init__()\n",
    "        self.net_body = net_body\n",
    "\n",
    "    def save(self, path, log=True):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        if log:\n",
    "            print('Saved model to `%s`' % path)\n",
    "\n",
    "    def load(self, path, log=True, **kwargs):\n",
    "        self.load_state_dict(torch.load(path, **kwargs))\n",
    "        if log:\n",
    "            print('Loaded model from `%s`' % path)\n",
    "\n",
    "    def get_device(self):\n",
    "        '''\n",
    "        Returns the `torch.device` on which the network resides.\n",
    "        This method only makes sense when all module parameters reside on the **same** device.\n",
    "        '''\n",
    "        return list(self.parameters())[0].device\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.net_body(*args, **kwargs)\n",
    "\n",
    "\n",
    "if args.dataset == 'mnist':\n",
    "    class EnergyNet(nn.Module):\n",
    "        def __init__(self, in_channels, act_fn=F.silu):\n",
    "            super().__init__()\n",
    "            self.act_fn = act_fn\n",
    "            self.conv1 = nn.Conv2d(in_channels, 6, 5)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "            self.pool = nn.AvgPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(self.act_fn(self.conv1(x)))\n",
    "            x = self.pool(self.act_fn(self.conv2(x)))\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.act_fn(self.fc1(x))\n",
    "            x = self.act_fn(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    net = Network(EnergyNet(in_channels=1)).to(args.device)\n",
    "else:\n",
    "    # class EnergyNet(nn.Module):\n",
    "    #     def __init__(self, in_width, act_fn=F.silu):\n",
    "    #         super().__init__()\n",
    "    #         self.act_fn = act_fn\n",
    "    #         self.fc_list = nn.ModuleList([\n",
    "    #             nn.Linear(in_width + 1, 300),\n",
    "    #             nn.Linear(300, 300),\n",
    "    #             nn.Linear(300, 1)\n",
    "    #         ])\n",
    "\n",
    "    #     def forward(self, x, t):\n",
    "    #         x = torch.concat([x, t[:, None]], dim=1)\n",
    "    #         depth = len(self.fc_list)\n",
    "    #         for i in range(depth):\n",
    "    #             x = self.fc_list[i](x)\n",
    "    #             x = self.act_fn(x) if i < depth - 1 else x\n",
    "    #         return x\n",
    "\n",
    "    # net = Network(EnergyNet(in_width=2)).to(args.device)\n",
    "\n",
    "    class EnergyNet(nn.Module):\n",
    "        def __init__(self, in_width, act_fn=F.relu):\n",
    "            super().__init__()\n",
    "            self.act_fn = act_fn\n",
    "            self.fc_list = nn.ModuleList([\n",
    "                nn.Linear(in_width, 300, bias=False),\n",
    "                nn.Linear(300, 300, bias=False),\n",
    "                nn.Linear(300, 1, bias=False)\n",
    "            ])\n",
    "\n",
    "        def forward(self, x, t):\n",
    "            x_in = x\n",
    "            # x = torch.concat([x, t[:, None]], dim=1)\n",
    "            depth = len(self.fc_list)\n",
    "            for i in range(depth):\n",
    "                x = self.fc_list[i](x)\n",
    "                x = self.act_fn(x) if i < depth - 1 else x\n",
    "            return x / torch.norm(x_in, dim=1, keepdim=True)\n",
    "\n",
    "    net = Network(EnergyNet(in_width=3)).to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy(ax, net, t):\n",
    "    from numpy import arange\n",
    "    from pylab import meshgrid, cm, imshow, colorbar, title, show\n",
    "    x = arange(-5.0, 5.0, 0.1)\n",
    "    y = arange(-5.0, 5.0, 0.1)\n",
    "    k = x.shape[0]\n",
    "    X, Y = meshgrid(x, y)\n",
    "    data = np.concatenate([X.reshape(-1, 1), Y.reshape(-1, 1)], axis=1)\n",
    "    with torch.no_grad():\n",
    "        data = torch.tensor(data, dtype=torch.float32, device=args.device)\n",
    "        t_tensor = torch.ones(data.shape[0], device=args.device) * t\n",
    "        Z = net(data, t_tensor).cpu().numpy().reshape(k, k)\n",
    "    im = ax.imshow(Z, cmap=cm.RdBu, extent=[-5, 5, -5, 5], origin='lower')\n",
    "    ax.set_title('Estimated Energy (t=%.2f)' % t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf figs_progress\n",
    "!mkdir figs_progress\n",
    "\n",
    "loss_list = []\n",
    "# plotlosses = PlotLosses()\n",
    "\n",
    "progress = tqdm(range(args.epochs), desc='Loss: None', total=args.epochs, position=0, leave=True)\n",
    "for epoch in progress:\n",
    "    cnt = 0\n",
    "    running_loss = 0.0\n",
    "    for x in train_loader:\n",
    "        if args.dataset == 'mnist':\n",
    "            x = x[0]\n",
    "        x = x.to(args.device)\n",
    "        x = project_on_sphere(x, r=5)\n",
    "\n",
    "        # t = args.min_noise + (args.max_noise - args.min_noise) * torch.rand(x.shape[0], device=args.device)\n",
    "        t = torch.ones(x.shape[0], device=args.device) * args.min_noise\n",
    "\n",
    "        noisy_x = add_noise(x, noise_strengths=t)\n",
    "        noise = noisy_x - x\n",
    "\n",
    "        noisy_x = noisy_x.requires_grad_()\n",
    "        energy_pred = net(noisy_x, t)\n",
    "        score = -torch.autograd.grad(energy_pred.sum(), noisy_x, create_graph=True)[0]\n",
    "\n",
    "        loss = torch.sum((score + noise / (t[:, None] ** 2)) ** 2) / (2 * args.batch_size)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cnt += 1\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    loss_list.append(running_loss / cnt)\n",
    "    progress.set_description(f'Loss: {loss_list[-1]:.4f}')\n",
    "\n",
    "    # fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    # plot_energy(ax[0], net, args.min_noise)\n",
    "    # plot_energy(ax[1], net, (args.min_noise + args.max_noise) / 2)\n",
    "    # plot_energy(ax[2], net, args.max_noise)\n",
    "    # fig.savefig(path.join('figs_progress', 'energy_%03d.png' % epoch), bbox_inches='tight', dpi=200)\n",
    "    # plt.show()\n",
    "\n",
    "    # plotlosses.update({\n",
    "    #     'score loss': loss_list[-1],\n",
    "    #     'noise loss': loss_noise_list[-1],\n",
    "    #     'total loss': loss_list[-1] + loss_noise_list[-1]\n",
    "    # })\n",
    "    # plotlosses.send()\n",
    "    # sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "plt.plot(loss_list, label='loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "files = sorted(glob.glob('figs_progress/*.png'))\n",
    "for file in files:\n",
    "    image_list.append(cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB))\n",
    "imageio.mimsave('ebm_training_progress_%s.gif' % args.dataset, image_list, fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load('ebm_%s.tar' % args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langevin_step_logp(x_, x, t, net, step_size):\n",
    "    x = x.requires_grad_()\n",
    "    energy_pred = net(x, t)\n",
    "    score = -torch.autograd.grad(energy_pred.sum(), x, create_graph=True)[0]\n",
    "    next_dist = torch.distributions.normal.Normal(loc=x + 0.5 * step_size * score, scale=np.sqrt(step_size))\n",
    "    return next_dist.log_prob(x_).sum(dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "def unadjusted_langevin_step(x, t, net, step_size):\n",
    "    t = torch.ones(x.shape[0], device=x.device) * t\n",
    "    x = x.requires_grad_()\n",
    "    energy_pred = net(x, t)\n",
    "    score = -torch.autograd.grad(energy_pred.sum(), x, create_graph=True)[0]\n",
    "    x = x + 0.5 * step_size * score + np.sqrt(step_size) * torch.randn_like(x)\n",
    "    return x.detach()\n",
    "\n",
    "\n",
    "def metropolis_adjusted_langevin_step(x, t, net, step_size):\n",
    "    t = torch.ones(x.shape[0], device=x.device) * t\n",
    "    x_ = unadjusted_langevin_step(x, t, net, step_size)\n",
    "    u = torch.rand((x.shape[0], 1), device=args.device)\n",
    "    k = langevin_step_logp(x, x_, t, net, step_size) + net(x, t) - langevin_step_logp(x_, x, t, net, step_size) - net(x_, t)\n",
    "    c = (torch.exp(k) < u) * 1.0\n",
    "    x_ = c * x_ + (1 - c) * x \n",
    "    return x_.detach()\n",
    "\n",
    "\n",
    "def annealed_langevin_sample(x0, t_sched, net, step_size_sched, n_steps, metropolis_adjusted=False):\n",
    "    x = x0\n",
    "    for step in range(n_steps):\n",
    "        if metropolis_adjusted:\n",
    "            x = metropolis_adjusted_langevin_step(x, t_sched(step), net, step_size_sched(step))\n",
    "        else:\n",
    "            x = unadjusted_langevin_step(x, t_sched(step), net, step_size_sched(step))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "T = 100\n",
    "L = 10\n",
    "eps = 2e-3\n",
    "# t_sched = lambda step: (args.min_noise / args.max_noise) ** ((step // T) / (L - 1)) * args.max_noise\n",
    "t_sched = lambda step: args.max_noise / (step + 1)\n",
    "\n",
    "x_hat = annealed_langevin_sample(\n",
    "    x0=torch.zeros((n, 2), device=args.device),\n",
    "    t_sched=t_sched,\n",
    "    net=net,\n",
    "    step_size_sched=lambda _: 0.1,  #lambda step: eps * (t_sched(step) / args.min_noise) ** 2,\n",
    "    n_steps=T * L,\n",
    "    metropolis_adjusted=True\n",
    ").cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample_2d(args.dataset, 1000)\n",
    "\n",
    "plt.scatter(x[:, 0], x[:, 1], s=1)\n",
    "plt.scatter(x_hat[:, 0], x_hat[:, 1], s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv_py38)",
   "language": "python",
   "name": "venv_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ef4de36560e0b347b1e3b04ff517523e5f1135d6ccd648dd419ad3c95ab5660"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
